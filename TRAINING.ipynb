{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81ade6c2-d756-41a1-8c74-86b337313d3a",
   "metadata": {},
   "source": [
    "# Import Pakages \n",
    "* numpy\n",
    "* tensorflow\n",
    "* matplotlib\n",
    "* pathlib\n",
    "* glob\n",
    "* Tcl\n",
    "* tensorflow_addons.layers\n",
    "* RandomNormal\n",
    "* Model\n",
    "* Input,Conv2D,Conv2DTranspose,LeakyReLU,Activation,Concatenate\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bee495-dae5-49e1-a256-3c7b57df1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import glob \n",
    "from tkinter import Tcl\n",
    "import tensorflow_addons.layers as tfal\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Conv2D,Conv2DTranspose,LeakyReLU,Activation,Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9376cc-0e73-4cae-bc52-f0830d7c1d4f",
   "metadata": {},
   "source": [
    "# PATHS OF DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a76a1-d566-416f-8f83-7607723476a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_t1 = pathlib.Path(r\"path of folder that contain T2 images\")\n",
    "data_dir_t2 = pathlib.Path(r\"path of folder that contain FLAIR images\")\n",
    "\n",
    "print(\"T2 MRI images: \",len(list(data_dir_t1.glob('*/*.png'))))\n",
    "print(\"FLAIR MRI images: \",len(list(data_dir_t2.glob('*/*.png'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78afc15e-d25f-4034-8a5d-d570af3b6745",
   "metadata": {},
   "source": [
    "# Initializing constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dbfcc3-9026-459d-8d66-e669b9cae639",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 400\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea697fb-9fa3-46eb-8d7c-9d7e49ea295c",
   "metadata": {},
   "source": [
    "# T2 MRI images Train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e25e34-c2f2-43a0-8d2a-97f87b122df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr1_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                              data_dir_t1,\n",
    "                              seed=123,\n",
    "                              validation_split = 0.06,\n",
    "                              subset = 'training',\n",
    "                              labels=None,\n",
    "                              image_size = (img_height, img_width),\n",
    "                              batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252121ed-7a8f-494b-83e0-5c3f5d636828",
   "metadata": {},
   "source": [
    "# T2 MRI images Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca890827-636e-4c8a-a856-74bd8461883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T2 MRI images Test set\n",
    "tr1_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                              data_dir_t1,\n",
    "                              seed=123,\n",
    "                              validation_split = 0.06,\n",
    "                              subset = 'validation',\n",
    "                              image_size=(img_height, img_width),\n",
    "                              batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a82cf-d59d-4fca-b740-ae46e2c44212",
   "metadata": {},
   "source": [
    "# FLAIR MRI images Train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cee48b-bbd4-49ec-903c-a6a65ff1391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                              data_dir_t2,\n",
    "                              seed=123,\n",
    "                              validation_split = 0.06,\n",
    "                              subset = 'training',\n",
    "                              labels=None,\n",
    "                              image_size = (img_height, img_width),\n",
    "                              batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99783559-0d2e-4dae-800e-22d584310430",
   "metadata": {},
   "source": [
    "# FLAIR MRI images Test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a0339-0eeb-4b58-bc87-8589a6115edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                              data_dir_t2,\n",
    "                              seed=123,\n",
    "                              validation_split = 0.06,\n",
    "                              subset = 'validation',\n",
    "                              image_size=(img_height, img_width),\n",
    "                              batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3057d2bd-083b-46c8-8e57-21dce3882d7a",
   "metadata": {},
   "source": [
    "# DATA LOADER :\n",
    "## DATA.cache()\n",
    "* method caches the dataset in memory or on disk after the first epoch\n",
    "## DATA.prefetch(buffer_size=AUTOTUNE)\n",
    "*overlaps the preprocessing and \n",
    "execution of the model during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fb18f2-eaf7-4860-b9a6-5caceb1be533",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tr1_train = tr1_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "tr1_test = tr1_test.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "tr2_train = tr2_train.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "tr2_test = tr2_test.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6444f456-8965-4529-a301-27c5a755eeb0",
   "metadata": {},
   "source": [
    "# normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21485589-3bbc-488a-a691-ab1110b358c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the images to [-1, 1]\n",
    "def normalize(image):\n",
    "    image = (image/127.5)-1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d303d-f13d-4103-802b-a489132e3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process both classes of MRI images\n",
    "tr1_train = tr1_train.map(lambda x: (normalize(x)))\n",
    "tr2_train = tr2_train.map(lambda x: (normalize(x)))\n",
    "tr1_test = tr1_test.map(lambda x,_: (normalize(x)))\n",
    "tr2_test = tr2_test.map(lambda x,_: (normalize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1563f0c5-35f4-4b1a-b26c-7cc832aaabd1",
   "metadata": {},
   "source": [
    "# sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d72bf5-0e45-4430-8d1c-718e07136e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_tr1 = next(iter(tr1_train))\n",
    "sample_tr2 = next(iter(tr2_train))\n",
    "\n",
    "print(sample_tr1.shape)\n",
    "\n",
    "\n",
    "plt.title('T2')\n",
    "plt.imshow(sample_tr1[0].numpy()[:, :, 0] * 0.5 + 0.5, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc72987-dec7-4c04-8515-4babc12e0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('FLAIR')\n",
    "plt.imshow(sample_tr2[0].numpy()[:, :, 0] * 0.5 + 0.5, cmap='gray')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e2727-42be-4a5d-89ca-4484e07bc255",
   "metadata": {},
   "source": [
    "# generator model \n",
    "* squeeze_attention_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e87b3d4-800a-404d-9c21-d17817e388e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(x, num_filters):\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = tfal.InstanceNormalization(axis=-1)(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = tfal.InstanceNormalization(axis=-1)(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def se_block(x, num_filters, ratio=8):\n",
    "    se_shape = (1, 1, num_filters)\n",
    "    se = L.GlobalAveragePooling2D()(x)\n",
    "    se = L.Reshape(se_shape)(se)\n",
    "    se = L.Dense(num_filters // ratio, activation=\"relu\", use_bias=False)(se)\n",
    "    se = L.Dense(num_filters, activation=\"sigmoid\", use_bias=False)(se)\n",
    "    se = L.Reshape(se_shape)(se)\n",
    "    x = L.Multiply()([x, se])\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, num_filters):\n",
    "    x = conv_block(x, num_filters)\n",
    "    x = se_block(x, num_filters)\n",
    "    p = L.MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(x, s, num_filters):\n",
    "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, num_filters)\n",
    "    x = se_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def squeeze_attention_unet(input_shape=(256, 256, 3)):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = L.Input(input_shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "    b1 = se_block(b1, 1024)\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d =  decoder_block(b1, s4, 512)\n",
    "    d1 = decoder_block(d, s3, 256)\n",
    "    d2 = decoder_block(d1, s2, 128)\n",
    "    d3 = decoder_block(d2, s1, 64)\n",
    "\n",
    "    \"\"\" Outputs \"\"\"\n",
    "    outputs = L.Conv2D(3, (1, 1), activation='tanh')(d3)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"Squeeze-Attention-UNET\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b12bf6-59ef-43c7-b2ae-afb387886592",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g = squeeze_attention_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6c64b-8a1c-4f5f-83ae-626b8fa5cbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4e17e4-7bd8-4bb3-af28-feb2faa35398",
   "metadata": {},
   "source": [
    "# DISCRIMINATOR \n",
    "* PATCH GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213fc25-566d-41d4-b4ae-759570146fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_norm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                               kernel_initializer=initializer, use_bias=False))\n",
    "    \n",
    "    if apply_norm:\n",
    "        result.add(tfal.InstanceNormalization(axis=-1))\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbe760-827e-493f-9e68-df1c65152cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    x = inp\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 16, 16, 64)\n",
    "    down2 = downsample(128, 4)(down1)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "    \n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "    norm1 = tfal.InstanceNormalization()(conv)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(3, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9890017-0143-443c-b6ea-dfb76522639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_x = discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff273d5-6199-4a4e-be56-fa789a569ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_x.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444b0e5a-69d8-478c-88a7-58a466bf3cef",
   "metadata": {},
   "source": [
    "## Performing Predicton on untrained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1d6bb-7418-4ccc-8830-a193687106c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tr2 = generator_g(sample_tr1)\n",
    "plt.figure(figsize=(8, 8))\n",
    "contrast = 8\n",
    "\n",
    "imgs = [sample_tr1, to_tr2, sample_tr2]\n",
    "title = ['tr1', 'To tr2', 'tr2']\n",
    "\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(title[i])\n",
    "    if i % 2 == 0:\n",
    "        plt.imshow(imgs[i][0].numpy()[:, :, 0] * 0.5 + 0.5, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(imgs[i][0].numpy()[:, :, 0] * 0.5 * contrast + 0.5, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971d95ba-dbac-4298-81c0-e7a4cc2476de",
   "metadata": {},
   "source": [
    "# LOSSES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b1906-aebd-4ad2-bb7b-1c696ac39d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA = 100.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ded80-8e65-4929-98a8-149db4308890",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(disc_real_output, disc_generated_output):\n",
    "    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
    "\n",
    "    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad939502-d8bd-4c78-b750-363ad68c0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\n",
    "    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
    "    # mean absolute error\n",
    "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
    "    l2_loss = 1 - tf.reduce_mean(tf.image.ssim(target, gen_output, max_val = 2.0))\n",
    "    l3_loss = (l1_loss + l2_loss) / 2\n",
    "    total_gen_loss = gan_loss + (LAMBDA * l3_loss)\n",
    "    return total_gen_loss, gan_loss, l3_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621186bd-6b63-43ee-8811-e874ace0a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5 ) # , beta_1=0.5\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5 ) # , beta_1=0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f75a4a-f3f5-4349-a946-7dff9f6a5a3a",
   "metadata": {},
   "source": [
    "# SAVING CHECK POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc443f1-dbed-49ad-bcf0-998ca6ef2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = r\"path of folder saving check points\"\n",
    "\n",
    "\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           \n",
    "                           discriminator_x=discriminator_x,\n",
    "                        \n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           \n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
    "                         )\n",
    "\n",
    "# Ref: https://www.tensorflow.org/api_docs/python/tf/train/CheckpointManager\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=300)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "\n",
    "    print(f'Last Check Point: {ckpt_manager.latest_checkpoint}')\n",
    "    print('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c119c070-0ffa-4ae5-b94f-3aaba9a73074",
   "metadata": {},
   "source": [
    "### SHOWING SAMPLE EVERY EPOCH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c605ac2-f36b-42ec-b30f-7b11ed911c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model1, test1,test2,  gen_g_loss, disc_x):\n",
    "    prediction1 = model1(test1)\n",
    "#     prediction2 = model2(test2)\n",
    "    \n",
    "    test1 = np.rot90(test1[0, :, :, 0], 3)\n",
    "    test2 = np.rot90(test2[0, :, :, 0], 3)\n",
    "    prediction1 = np.rot90(prediction1[0, :, :, 0], 3)\n",
    "#     prediction2 = np.rot90(prediction2[0, :, :, 0], 3)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    display_list = [test1, prediction1, test2]\n",
    "    \n",
    "    title = ['T2 True', 'FALIR predicted', 'FLAIR True']\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.text(-600, 300 ,\"gen_g_er = {:.3f}, disc_x_er = {:.3f}\".format(gen_g_loss, disc_x))\n",
    "    plt.savefig(r'path of saving images/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042805f-ab33-4298-a996-3e2628e01ebd",
   "metadata": {},
   "source": [
    "# Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a57ab5-1800-4db4-90cc-5db0d29a3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://www.tensorflow.org/guide/function\n",
    "@tf.function\n",
    "def train_step(real_x, real_y):\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        disc_real_x = discriminator_x(real_y, training=True)\n",
    "#         disc_real_y = discriminator_y(real_y, training=True)\n",
    "        \n",
    "        disc_fake_x = discriminator_x(fake_y, training=True)\n",
    "#         disc_fake_y = discriminator_y(fake_y, training=True)\n",
    "\n",
    "        # calculate the loss\n",
    "        total_gen_g_loss = generator_loss(disc_fake_x,fake_y,real_y)\n",
    "#         gen_f_loss = generator_loss(disc_fake_x)\n",
    "                \n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "        \n",
    "    # Calculate the gradients for generator and discriminator\n",
    "    generator_g_gradients = tape.gradient(total_gen_g_loss, generator_g.trainable_variables)\n",
    "    \n",
    "    discriminator_x_gradients = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)\n",
    "    \n",
    "    # Apply the gradients to the optimizer\n",
    "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients, generator_g.trainable_variables))\n",
    "    \n",
    "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
    "    \n",
    "    return total_gen_g_loss, disc_x_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71564229-daf5-47b7-bfb7-72e70a20e6b5",
   "metadata": {},
   "source": [
    "# Test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09b2ef-0163-470d-99f1-7035bbcc3a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(real_x, real_y):\n",
    "    # persistent is set to True because the tape is used more than\n",
    "    # once to calculate the gradients.\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Generator G translates X -> Y\n",
    "        fake_y = generator_g(real_x, training=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        disc_real_x = discriminator_x(real_y, training=True)\n",
    "        \n",
    "        disc_fake_x = discriminator_x(fake_y, training=True)\n",
    "\n",
    "        # calculate the loss\n",
    "        total_gen_g_loss = generator_loss(disc_fake_x,fake_y,real_y)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Total generator loss = adversarial loss + cycle loss\n",
    "  \n",
    "        \n",
    "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
    "#         total_gen_g_loss = gen_g_loss + (total_cycle_loss + identity_loss(real_y, same_y)) / 10.0\n",
    "#         total_gen_f_loss = gen_f_loss + (total_cycle_loss + identity_loss(real_x, same_x)) / 10.0\n",
    "    \n",
    "    return total_gen_g_loss, disc_x_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024543ac-8770-425c-9e07-e11bba5bca0c",
   "metadata": {},
   "source": [
    "## text saving the history of training and validation losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515789b6-9287-44aa-ab23-239e669e0a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history of generator loss (training)\n",
    "history_gen_1 = []\n",
    "# history of discrimnitor loss (training)\n",
    "history_dis_1 = []\n",
    "# history of generator loss (validation)\n",
    "val_g_hist_1 = []\n",
    "# history of discrimnitor loss (validation)\n",
    "val_d_hist_1 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd159669-79a3-4f92-ae0b-bbb704502d19",
   "metadata": {},
   "source": [
    "# STRAT TRAINING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699aedda-e636-4c91-816e-ab45798c8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS+1):\n",
    "    gen_g_loss = 0\n",
    "    gen_f_loss = 0\n",
    "    disc_x = 0\n",
    "    disc_y = 0\n",
    "    for image_x,image_y in tf.data.Dataset.zip((tr1_train,tr2_train)):\n",
    "        gen_g_loss_temp, disc_x_temp = train_step(image_x,image_y)\n",
    "        gen_g_loss = gen_g_loss + gen_g_loss_temp[0]  / 19289          * BATCH_SIZE\n",
    "        disc_x = disc_x + disc_x_temp / 19289          * BATCH_SIZE\n",
    "        \n",
    "    tot_loss_gen = gen_g_loss \n",
    "    tot_loss_dis = disc_x \n",
    "\n",
    "\n",
    "\n",
    "    history_gen_1.append([tot_loss_gen])\n",
    "    history_dis_1.append([tot_loss_dis])\n",
    "\n",
    "\n",
    "\n",
    "    np.savetxt(r'path of saving text/history_gen.txt_1', history_gen_1, fmt='%f')\n",
    "    np.savetxt(r'path of saving text/history_dis.txt_1', history_dis_1, fmt='%f')\n",
    "\n",
    "    generate_images(generator_g, sample_tr1, sample_tr2, tot_loss_gen, disc_x)\n",
    "\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print('Saving checkpoint for epoch', epoch, 'at', ckpt_save_path)\n",
    "    gen_g_loss = 0\n",
    "    gen_f_loss = 0\n",
    "    disc_x = 0\n",
    "    disc_y = 0\n",
    "    for image_x ,image_y in tf.data.Dataset.zip((tr1_test , tr2_test)):\n",
    "        gen_g_loss_temp, disc_x_temp = test_step(image_x,image_y)\n",
    "        gen_g_loss = gen_g_loss + gen_g_loss_temp[0]  / 1231   * BATCH_SIZE\n",
    "        disc_x = disc_x + disc_x_temp / 1231   * BATCH_SIZE\n",
    "    tot_loss_gen = gen_g_loss \n",
    "    tot_loss_dis = disc_x \n",
    "\n",
    "    val_g_hist_1.append([tot_loss_gen])\n",
    "    val_d_hist_1.append([tot_loss_dis])\n",
    "\n",
    "  \n",
    "    np.savetxt(r'path of saving text/val_g_hist_1.txt_1', val_g_hist_1, fmt='%f')\n",
    "    np.savetxt(r'path of saving text/val_d_hist_1.txt_1', val_d_hist_1, fmt='%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
