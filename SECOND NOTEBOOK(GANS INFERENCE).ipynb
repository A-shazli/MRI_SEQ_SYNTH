{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23b990e",
   "metadata": {
    "id": "a23b990e"
   },
   "source": [
    "# Imports and Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c77b0-200b-423b-a9e5-7f6af898210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pathlib\n",
    "import imageio\n",
    "import glob\n",
    "import PIL\n",
    "import nibabel as nib\n",
    "import os\n",
    "from tkinter import Tcl\n",
    "import cv2\n",
    "import tensorflow_docs.vis.embed as embed\n",
    "import tensorflow_addons.layers as tfal\n",
    "from keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Conv2D,Conv2DTranspose,LeakyReLU,Activation,Concatenate,Add\n",
    "from scipy import ndimage\n",
    "import shutil\n",
    "import json\n",
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FiYaET3uZst2",
   "metadata": {
    "id": "FiYaET3uZst2"
   },
   "source": [
    "# Further helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zODj5gQguc5I",
   "metadata": {
    "id": "zODj5gQguc5I"
   },
   "outputs": [],
   "source": [
    "#Normalization of images for the synthesis model training and testing\n",
    "def preprocess_image_train(image):\n",
    "    image = (image/127.5)-1\n",
    "    return image\n",
    "\n",
    "# This function is to generate the GIF images throughout the training schedule\n",
    "def generate_images_GIF(img_input, model, img_true, mode, order):\n",
    "    prediction = model(img_input)\n",
    "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
    "    error = tf.image.ssim(img_true, prediction, max_val=2)\n",
    "    img_input = np.rot90(img_input[0, :, :, 0], 3)\n",
    "    img_true = np.rot90(img_true[0, :, :, 0], 3)\n",
    "    prediction = np.rot90(prediction[0, :, :, 0], 3)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if mode == 1:\n",
    "        display_list = [img_input, prediction, img_true]\n",
    "        title = [f'{seq_1} True', f'{seq_2} predicted', f'{seq_2} True']\n",
    "\n",
    "    else:\n",
    "        display_list = [img_input, prediction, img_true]\n",
    "        title = [f'{seq_2} True', f'{seq_1} predicted', f'{seq_1} True']\n",
    "\n",
    "    plots_path_T1_FLAIR = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF'.format(brats_num, seq_1,\n",
    "                                                                                                       seq_2)\n",
    "    plots_path_FLAIR_T1 = r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF'.format(brats_num, seq_2,\n",
    "                                                                                                       seq_1)\n",
    "    if not os.path.exists(plots_path_T1_FLAIR):\n",
    "        os.makedirs(plots_path_T1_FLAIR)\n",
    "    if not os.path.exists(plots_path_FLAIR_T1):\n",
    "        os.makedirs(plots_path_FLAIR_T1)\n",
    "\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i] * 0.5 + 0.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        if mode == 1:\n",
    "            plt.savefig(\n",
    "                r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF\\{}.png'.format(brats_num, seq_1,\n",
    "                                                                                                    seq_2, order))\n",
    "        if mode == 2:\n",
    "            plt.savefig(\n",
    "                r'E:\\Graduation Project\\GIFs and Models\\Brats {}\\Predicted\\{}-{}-GIF\\{}.png'.format(brats_num, seq_2,\n",
    "                                                                                                    seq_1, order))\n",
    "    plt.show()\n",
    "    return error, pred_vol\n",
    "\n",
    "# Predicting (generating) the images, without calculating the loss\n",
    "def predict_image(img_input, model):\n",
    "    prediction = model(img_input)\n",
    "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
    "    return pred_vol\n",
    "\n",
    "def predict_image(img_input, model, img_true):\n",
    "    prediction = model(img_input)\n",
    "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
    "    # error = tf.image.ssim(img_true, prediction, max_val=2)\n",
    "    return 0, pred_vol\n",
    "\n",
    "# Predicting (generating) the images, and calculating the loss\n",
    "def predict_image_and_calc_loss(img_input, model, img_true):\n",
    "    prediction = model(img_input)\n",
    "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
    "    # error = tf.image.ssim(img_true, prediction, max_val=2)\n",
    "    return 0, pred_vol\n",
    "\n",
    "def predict_image_and_NO_loss(img_input, model):\n",
    "    prediction = model(img_input)\n",
    "    pred_vol = prediction[0, :, :, 0].numpy().copy()\n",
    "    return pred_vol\n",
    "\n",
    "# generate black sequences in the same shape as the other input sequences with the heirarchy and name format, to be used in segmentation comparison cases\n",
    "def black_seq_generator(test_path, brats_num, T1_FLAG=True, T2_FLAG=True, FLAIR_FLAG=True):\n",
    "    test_data_list = sorted(glob.glob(test_path + '/*'))\n",
    "    original_vol_path = sorted(glob.glob(test_path + '/*'))[0]\n",
    "    original_vol = nib.load(original_vol_path)\n",
    "    original_shape = original_vol.shape\n",
    "\n",
    "    v = np.zeros(original_shape)\n",
    "    v = nib.Nifti1Image(v, original_vol.affine)  # to save this 3D (ndarry) numpy\n",
    "\n",
    "    if FLAIR_FLAG:\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_flair.nii.gz')\n",
    "    if T1_FLAG:\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t1.nii.gz')\n",
    "    if T2_FLAG:\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t2.nii.gz')\n",
    "\n",
    "    if T1_FLAG and T2_FLAG:\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t1.nii.gz')\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t2.nii.gz')\n",
    "    if T1_FLAG and FLAIR_FLAG:\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t1.nii.gz')\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_flair.nii.gz')\n",
    "    if T2_FLAG and FLAIR_FLAG:\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_flair.nii.gz')\n",
    "        nib.save(v, test_path + '/' + f'BraTS2021_0{brats_num:04d}_t2.nii.gz')\n",
    "    print(\"Done\")\n",
    "\n",
    "def copy_subfolders_into_another_folder(paths_txt, source_folder, destination_folder):\n",
    "    # Read the contents of the file\n",
    "    with open(paths_txt, 'r') as file:\n",
    "        contents = file.read()\n",
    "\n",
    "    # Replace single quotes with double quotes\n",
    "    contents = contents.replace(\"'\", \"\\\"\")\n",
    "\n",
    "    # Load the JSON array, the list of subfolder names to copy\n",
    "    subfolder_names = json.loads(contents)\n",
    "\n",
    "    # Loop through each item in the source folder\n",
    "    for item in os.listdir(source_folder):\n",
    "        # If the item is a subfolder and its name is in the list\n",
    "        if os.path.isdir(os.path.join(source_folder, item)) and item in subfolder_names:\n",
    "            # Copy the subfolder to the destination folder\n",
    "            shutil.copytree(os.path.join(source_folder, item), os.path.join(destination_folder, item))\n",
    "\n",
    "    copy_subfolders_into_another_folder\n",
    "\n",
    "# The following function is responsible for returning the indices of the brain of the volume that contains foreground voxels.\n",
    "def find_brain_width_wise(dep, hei, i, img):        #cropping width wise\n",
    "    slice2D = img.get_fdata()[:, i, :]\n",
    "    for j in range(hei):\n",
    "        for k in range(dep):\n",
    "            if slice2D[j, k] != 0:\n",
    "                return i\n",
    "    return 0\n",
    "\n",
    "def find_brain_height_wise(dep, wid, i, img):      #cropping height wise\n",
    "    slice2D = img.get_fdata()[i, :, :]\n",
    "    for j in range(wid):\n",
    "        for k in range(dep):\n",
    "            if slice2D[j, k] != 0:\n",
    "                return i\n",
    "    return 0\n",
    "\n",
    "def find_brain_depth_wise(wid, hei, i, img):        #cropping depth wise\n",
    "    slice2D = img.get_fdata()[:, :, i]\n",
    "    for j in range(wid):\n",
    "        for k in range(hei):\n",
    "            if slice2D[j, k] != 0:\n",
    "                return i\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73677a6",
   "metadata": {
    "id": "f73677a6"
   },
   "source": [
    "###   Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9-Uk1K-6yf5W",
   "metadata": {
    "id": "9-Uk1K-6yf5W"
   },
   "outputs": [],
   "source": [
    "root_path = r'Path Of BraTS Validation Brain Cropped Volumes'\n",
    "data_list = sorted(glob.glob(root_path + '/*'))                       #list of paths of the inside subjects\n",
    "\n",
    "results_path = r'Path Of BraTS Validation Brain Cropped 2D Images '\n",
    "results_data_list = sorted(glob.glob(results_path + '/*'))            #list of all (IMAGES) for each sequence for each subject\n",
    "\n",
    "\n",
    "data_list, results_data_list\n",
    "# To double check the size of our Data\n",
    "len(sorted(glob.glob(results_path + '/*')))\n",
    "seq_1 = 'T2'\n",
    "seq_2 = 'FLAIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43eeea-7164-4c50-bd9c-743d5c7f3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list, results_data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o7yNXSWkZ73J",
   "metadata": {
    "id": "o7yNXSWkZ73J"
   },
   "source": [
    "# The current in-use model archeticture, Squeeze and Excitation Attention GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da389c8b-895e-4e1e-a4a9-5a5d12f68c13",
   "metadata": {},
   "source": [
    "# GENERATOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb39f4-0911-4b83-86c3-e09f256cdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(x, num_filters):\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = tfal.InstanceNormalization(axis=-1)(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = tfal.InstanceNormalization(axis=-1)(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def se_block(x, num_filters, ratio=8):\n",
    "    se_shape = (1, 1, num_filters)\n",
    "    se = L.GlobalAveragePooling2D()(x)\n",
    "    se = L.Reshape(se_shape)(se)\n",
    "    se = L.Dense(num_filters // ratio, activation=\"relu\", use_bias=False)(se)\n",
    "    se = L.Dense(num_filters, activation=\"sigmoid\", use_bias=False)(se)\n",
    "    se = L.Reshape(se_shape)(se)\n",
    "    x = L.Multiply()([x, se])\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, num_filters):\n",
    "    x = conv_block(x, num_filters)\n",
    "    x = se_block(x, num_filters)\n",
    "    p = L.MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(x, s, num_filters):\n",
    "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, num_filters)\n",
    "    x = se_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def squeeze_attention_unet(input_shape=(256, 256, 3)):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = L.Input(input_shape)\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "    b1 = se_block(b1, 1024)\n",
    "    \n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d =  decoder_block(b1, s4, 512)\n",
    "    d1 = decoder_block(d, s3, 256)\n",
    "    d2 = decoder_block(d1, s2, 128)\n",
    "    d3 = decoder_block(d2, s1, 64)\n",
    "\n",
    "    \"\"\" Outputs \"\"\"\n",
    "    outputs = L.Conv2D(3, (1, 1), activation='tanh')(d3)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"Squeeze-Attention-UNET\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db1826a-e154-4263-81c0-7c8101c3a4db",
   "metadata": {},
   "source": [
    "# DISCRIMINATOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547a976-4590-43f7-a529-605a9208970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_norm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
    "                                               kernel_initializer=initializer, use_bias=False))\n",
    "    \n",
    "    if apply_norm:\n",
    "        result.add(tfal.InstanceNormalization(axis=-1))\n",
    "    result.add(tf.keras.layers.LeakyReLU())\n",
    "  #  result.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2, padding='same' ))\n",
    "    return result\n",
    "\n",
    "\n",
    "def discriminator():\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')\n",
    "    x = inp\n",
    "    down1 = downsample(64, 4, False)(x) # (bs, 16, 16, 64)\n",
    "    down2 = downsample(128, 4)(down1)\n",
    "    down3 = downsample(256, 4)(down2)\n",
    "    \n",
    "\n",
    "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
    "    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
    "                                  use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
    "    norm1 = tfal.InstanceNormalization()(conv)\n",
    "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
    "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
    "\n",
    "    last = tf.keras.layers.Conv2D(3, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
    "    return tf.keras.Model(inputs=inp, outputs=last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829c2ce-647f-4379-9f0a-f31e31cb1795",
   "metadata": {},
   "source": [
    "# CHECK POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7799c553-8d18-40fc-8c6b-9927c616f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generator_g = squeeze_attention_unet()\n",
    "discriminator_x = discriminator()\n",
    "generator_g_optimizer = tf.keras.optimizers.legacy.Adam(2e-10, beta_1=0.5 )\n",
    "discriminator_x_optimizer = tf.keras.optimizers.legacy.Adam(2e-10, beta_1=0.5 )\n",
    "\n",
    "\n",
    "# Loading the \"GANs\" model\n",
    "checkpoint_path = r\"Path of the Last Check Model\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
    "                           discriminator_x=discriminator_x,\n",
    "                           generator_g_optimizer=generator_g_optimizer,\n",
    "                           discriminator_x_optimizer=discriminator_x_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=300)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print(f'Last Check Point: {ckpt_manager.latest_checkpoint}')\n",
    "    print('Latest checkpoint restored!!')\n",
    "\n",
    "print(\"Generator's parameters = {:,}\".format(generator_g.count_params()))\n",
    "print(\"Discriminator's parameters = {:,}\".format(discriminator_x.count_params()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c5c23",
   "metadata": {
    "id": "0d9c5c23"
   },
   "source": [
    "# Copy from root to result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icoC1Jeeh0MR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "icoC1Jeeh0MR",
    "outputId": "705d694d-6356-4d6a-e653-cf05d395f499"
   },
   "outputs": [],
   "source": [
    "root_path, results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EgC2ufsqF7EU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgC2ufsqF7EU",
    "outputId": "4391d430-acc3-470b-e588-862bf639f761"
   },
   "outputs": [],
   "source": [
    "#our results path, in this case, for africa brats (synthesizing flair from t2)\n",
    "FLAIR_syn_result_vol_path = r'Path of Saved The prediction volumes'\n",
    "\n",
    "# results_data_list = sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))\n",
    "\n",
    "# Get a list of all the subfolders in the source folder\n",
    "subfolders = [f.path for f in os.scandir(root_path) if f.is_dir()]\n",
    "\n",
    "# Copy each subfolder to the destination folders\n",
    "for folder in subfolders:\n",
    "    shutil.copytree(folder, os.path.join(FLAIR_syn_result_vol_path, os.path.basename(folder)))\n",
    "\n",
    "print(len(glob.glob(FLAIR_syn_result_vol_path + '/*')))\n",
    "FLAIR_syn_result_vols = sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))\n",
    "\n",
    "#count the number of file (double checking that everything is going well)\n",
    "total_files = 0\n",
    "for root, dirs, files in os.walk(FLAIR_syn_result_vol_path):\n",
    "    total_files += len(files)\n",
    "print('Total number of files in folder and subfolders:', total_files)\n",
    "\n",
    "#double checking that for each subfolder, I have all 4 sequences + the segmentation\n",
    "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
    "  x = len( sorted(glob.glob(i + '/*')))\n",
    "  if x != 5:\n",
    "    print(i)\n",
    "print(len(FLAIR_syn_result_vols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b109c3",
   "metadata": {
    "id": "d2b109c3"
   },
   "source": [
    "# Delete T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eced285",
   "metadata": {
    "id": "0eced285"
   },
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(T1_syn_result_vol_path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('t1.nii.gz'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            os.remove(file_path)\n",
    "#             print(f\"{file_path} has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37212bc0",
   "metadata": {
    "id": "37212bc0"
   },
   "source": [
    "# Delete T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef106373",
   "metadata": {
    "id": "ef106373"
   },
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(T2_syn_result_vol_path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('t2.nii.gz'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            os.remove(file_path)\n",
    "#             print(f\"{file_path} has been deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d88397",
   "metadata": {
    "id": "92d88397"
   },
   "source": [
    "# Delete FLAIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72567345",
   "metadata": {
    "id": "72567345"
   },
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(FLAIR_syn_result_vol_path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('flair.nii.gz'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44IY9ji_FUDh",
   "metadata": {
    "id": "44IY9ji_FUDh"
   },
   "source": [
    "# Delete T1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s8WgHNjUFTFR",
   "metadata": {
    "id": "s8WgHNjUFTFR"
   },
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(FLAIR_syn_result_vol_path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('t1ce.nii.gz'):\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SBCvtwBIe9k3",
   "metadata": {
    "id": "SBCvtwBIe9k3"
   },
   "source": [
    "### double checking that for each subfolder, I have ONLY 3 sequences (as one sequence should be deleted to be predicted later) + the segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "V5gjysc22CH9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5gjysc22CH9",
    "outputId": "8b0fa87f-4629-4f43-bb5a-22e95f388eac"
   },
   "outputs": [],
   "source": [
    "for i in (sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))):\n",
    "  x = len(sorted(glob.glob(i + '/*')))\n",
    "  if x != 4:\n",
    "    print(i)\n",
    "\n",
    "total_files = 0\n",
    "for root, dirs, files in os.walk(FLAIR_syn_result_vol_path):\n",
    "    total_files += len(files)\n",
    "\n",
    "print('Total number of files in folder and subfolders:', total_files)\n",
    "\n",
    "print(len(sorted(glob.glob(FLAIR_syn_result_vol_path + '/*'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hM549FX_d8Ih",
   "metadata": {
    "id": "hM549FX_d8Ih"
   },
   "outputs": [],
   "source": [
    "SSIM1 = []\n",
    "SSIM2 = []\n",
    "\n",
    "vol_1 = []\n",
    "vol_2 = []\n",
    "\n",
    "ssim_1_list = []\n",
    "ssim_2_list = []\n",
    "\n",
    "order_1 = 0\n",
    "order_2 = 0\n",
    "\n",
    "ssim_score_1 = 0\n",
    "ssim_score_2 = 0\n",
    "\n",
    "seq_1 = 'T2'\n",
    "seq_2 = 'FLAIR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nVFajrYYln6L",
   "metadata": {
    "id": "nVFajrYYln6L"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "for i, path in enumerate(results_data_list):\n",
    "    T1_path = os.path.join(path, \"images\", \"GIF T2\")\n",
    "    dep = len(glob.glob(T1_path + '/**/*'))\n",
    "\n",
    "    GIF_T1 = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                  T1_path,\n",
    "                                  seed=123,\n",
    "                                  image_size=(256, 256),\n",
    "                                  batch_size=1,\n",
    "                                  shuffle = False)\n",
    "\n",
    "    GIF_T1 = GIF_T1.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    GIF_T1 = GIF_T1.map(lambda x, _: (preprocess_image_train(x)))\n",
    "\n",
    "    for image_x in GIF_T1:\n",
    "        img_1 = predict_image_and_NO_loss(image_x, generator_g)\n",
    "        vol_2.append(img_1)\n",
    "\n",
    "    original_vol_path = sorted(glob.glob(data_list[i] + '/*'))[0]\n",
    "    original_vol = nib.load(original_vol_path)\n",
    "    original_shape = original_vol.shape\n",
    "\n",
    "    vol_2 = np.array(vol_2).transpose(1, 2, 0)\n",
    "\n",
    "    vol_2 = ndimage.zoom(vol_2, (original_shape[0]/vol_2.shape[0],\n",
    "                                 original_shape[1]/vol_2.shape[1],\n",
    "                                 original_shape[2]/vol_2.shape[2]), order=0)\n",
    "\n",
    "    v2 = nib.Nifti1Image(np.array(vol_2), original_vol.affine)\n",
    "    FLAIR_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[0])  #for flair\n",
    "    # FLAIR_name = os.path.basename(sorted(glob.glob(data_list[i] + '/*'))[3])   #for T1ce\n",
    "\n",
    "    FLAIR_res_path = os.path.join(FLAIR_syn_result_vols[i], FLAIR_name)\n",
    "    nib.save(v2, FLAIR_res_path)\n",
    "\n",
    "    vol_1 = []\n",
    "    vol_2 = []\n",
    "    print(f\"Volume #{i} is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-7uSfApVgNlg",
   "metadata": {
    "id": "-7uSfApVgNlg"
   },
   "source": [
    "#### The following cell is to ZIP the results dataset (now containing, for each subject, 3 original sequences, 1 synthesized sequence, corresponding segmentation map), to be used in segmentation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2HTj9yofpClo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HTj9yofpClo",
    "outputId": "fe350c8d-5ff8-47a0-9d65-10d9fa6d46d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping complete.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source_folder_path = r'Path of Saved The prediction volumes'\n",
    "destination_folder_path = r'Path of Saved The prediction volumes as Zip'\n",
    "zip_filename = 'syn'\n",
    "zip_filepath = os.path.join(destination_folder_path, zip_filename)\n",
    "shutil.make_archive(zip_filepath, 'zip', source_folder_path)\n",
    "print(\"Zipping complete.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
